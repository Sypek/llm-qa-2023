{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain --quiet\n",
    "!pip install unstructured --quiet\n",
    "!pip install \"unstructured[md]\" --quiet\n",
    "!pip install chromadb --quiet\n",
    "!pip install -U boto3 --quiet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from typing import Dict, List\n",
    "\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader, DirectoryLoader\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STACK = 'LLMStack'\n",
    "INPUT_DATA_LOCAL_DIR = 'input_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cf_config(stackname: str):\n",
    "    cf_client = boto3.client('cloudformation')\n",
    "\n",
    "    response = cf_client.describe_stacks(StackName=stackname)\n",
    "    outputs = response[\"Stacks\"][0][\"Outputs\"]\n",
    "\n",
    "    cf_outputs = {}\n",
    "    for i in outputs:\n",
    "        cf_outputs[i['OutputKey']] = i['OutputValue']\n",
    "    return cf_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_config = get_cf_config(STACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files_from_s3(bucket_name, dir_name: str = 'input_data'):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "        \n",
    "    s3_client = boto3.client('s3')\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    objs = bucket.objects.filter(Prefix=dir_name)\n",
    "    for obj in objs:\n",
    "        s3_client.download_file(bucket_name, obj.key, obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_files_from_s3(stack_config['S3BucketName'], INPUT_DATA_LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(INPUT_DATA_LOCAL_DIR,\n",
    "                         loader_cls=UnstructuredMarkdownLoader,\n",
    "                         show_progress=True,\n",
    "                         use_multithreading=True)\n",
    "\n",
    "docs = loader.load()\n",
    "print(f'Lazy loaded {len(docs)} docs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_splitter = MarkdownTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "texts = md_splitter.split_documents(docs)\n",
    "print(f'There are {len(texts)} texts after splitting.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentHandler(EmbeddingsContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"text_inputs\": inputs, **model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_handler = ContentHandler()\n",
    "\n",
    "embeddings = SagemakerEndpointEmbeddings( \n",
    "    endpoint_name=stack_config['SageMakerEndpointEmbeddings'],\n",
    "    region_name=stack_config['AWSRegion'],\n",
    "    content_handler=content_handler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_dir = 'chroma'\n",
    "\n",
    "if not os.path.exists(chroma_dir):\n",
    "    os.makedirs(chroma_dir)\n",
    "else:\n",
    "    shutil.rmtree(chroma_dir)\n",
    "\n",
    "doc_search = Chroma.from_documents(\n",
    "    texts,\n",
    "    embeddings,\n",
    "    persist_directory=chroma_dir,\n",
    "    collection_name='sagemaker_docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save chroma db to S3\n",
    "bucket_name = stack_config['S3BucketName']\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "\n",
    "def upload_to_s3(local_file, s3_bucket, s3_object_name):\n",
    "    s3.upload_file(local_file, s3_bucket, s3_object_name)\n",
    "    print(f\"Uploaded {local_file} to {s3_bucket}/{s3_object_name}\")\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(chroma_dir):\n",
    "    for file in files:\n",
    "        local_path = os.path.join(root, file)\n",
    "        upload_to_s3(local_path, bucket_name, local_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
